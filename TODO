* Use the subscope variable to allow quicker searches over subsets of
the data. Support just integers at first (that's all I need for now),
maybe add support for hashing strings and/or multiple values together
later.

* Watch out for interactions between fuzzy_search_limit and scopes.
If the first 25 results from the search don't fit the scope, the
user will end up with an empty result set.

* If it doesn't slow things up too much, prefer short matches when given
short query strings, i.e. "ama" should rank "Amad" higher than
"Amalamadingdongwitcherydoo".  Can do this by using the total
number of trigrams for the given record (or maybe a given word?)
as a secondary order field.

* Phonetic coding (i.e metaphone). Needs to be all-or-nothing
for any given AR model, otherwise we'd have to try searching
on both coded and raw versions of each query string to match
against both coded and non-coded properties, which would
throw away the optimization (although it would still allow
for phonetic near-matches, which is cool).

Maybe can make this a user-adjustable thing by bringing
back the 'specify a normalize method' feature.

* Maybe allow a [trigram,rec_id] to appear multiple times
under different subsets? Just have to make sure my scoring
rule counts only unique trigram hits.
